{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement of SSD in Keras\n",
    "SSD: Single Shot Multibox Detector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an one-stage detector, SSD use the multi-layer feature map extracted by VGG16 to address the detection of objects with different sizes. The new concept in SSD is default box, which is similar to the 'anchors' in Faster R-CNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basenetwork is used to extract feature maps of the image, and is based on VGG16. The changes from VGG16 is, change FC6 and FC7 to two conv networks.  And add four more conv networks to construct the framework of the model.\n",
    "![title](img/yolovsssd.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 feature maps used to predict bounding box and class. The overall predicted bounding box adds up to 8732.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the implementation of modified VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSD300(input_shape, num_classes=21):\n",
    "#Input_shape 300,300,3ï¼‰\n",
    "#num_class is the number of classes that is need to be detected.\n",
    " # Block 1\n",
    "    input_tensor = input_tensor = Input(shape=input_shape)\n",
    "    img_size = (input_shape[1], input_shape[0])\n",
    "    net['input'] = input_tensor\n",
    "    net['conv1_1'] = Convolution2D(64, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv1_1')(net['input'])\n",
    "    net['conv1_2'] = Convolution2D(64, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv1_2')(net['conv1_1'])\n",
    "    net['pool1'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n",
    "                                name='pool1')(net['conv1_2'])\n",
    "    # Block 2\n",
    "    net['conv2_1'] = Convolution2D(128, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv2_1')(net['pool1'])\n",
    "    net['conv2_2'] = Convolution2D(128, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv2_2')(net['conv2_1'])\n",
    "    net['pool2'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n",
    "                                name='pool2')(net['conv2_2'])\n",
    "    # Block 3\n",
    "    net['conv3_1'] = Convolution2D(256, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv3_1')(net['pool2'])\n",
    "    net['conv3_2'] = Convolution2D(256, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv3_2')(net['conv3_1'])\n",
    "    net['conv3_3'] = Convolution2D(256, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv3_3')(net['conv3_2'])\n",
    "    net['pool3'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n",
    "                                name='pool3')(net['conv3_3'])\n",
    "    # Block 4\n",
    "    net['conv4_1'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv4_1')(net['pool3'])\n",
    "    net['conv4_2'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv4_2')(net['conv4_1'])\n",
    "    net['conv4_3'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv4_3')(net['conv4_2'])\n",
    "    net['pool4'] = MaxPooling2D((2, 2), strides=(2, 2), border_mode='same',\n",
    "                                name='pool4')(net['conv4_3'])\n",
    "    # Block 5\n",
    "    net['conv5_1'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv5_1')(net['pool4'])\n",
    "    net['conv5_2'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv5_2')(net['conv5_1'])\n",
    "    net['conv5_3'] = Convolution2D(512, 3, 3,\n",
    "                                   activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv5_3')(net['conv5_2'])\n",
    "    net['pool5'] = MaxPooling2D((3, 3), strides=(1, 1), border_mode='same',\n",
    "                                name='pool5')(net['conv5_3'])\n",
    "    # ***FC6***\n",
    "    net['fc6'] = AtrousConvolution2D(1024, 3, 3, atrous_rate=(6, 6),\n",
    "                                     activation='relu', border_mode='same',\n",
    "                                     name='fc6')(net['pool5'])\n",
    "    # ***FC7***\n",
    "    net['fc7'] = Convolution2D(1024, 1, 1, activation='relu',\n",
    "                               border_mode='same', name='fc7')(net['fc6'])\n",
    "    # Block 6\n",
    "    net['conv6_1'] = Convolution2D(256, 1, 1, activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv6_1')(net['fc7'])\n",
    "    net['conv6_2'] = Convolution2D(512, 3, 3, subsample=(2, 2),\n",
    "                                   activation='relu', border_mode='same',\n",
    "                                   name='conv6_2')(net['conv6_1'])\n",
    "    # Block 7\n",
    "    net['conv7_1'] = Convolution2D(128, 1, 1, activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv7_1')(net['conv6_2'])\n",
    "    net['conv7_2'] = ZeroPadding2D()(net['conv7_1'])\n",
    "    net['conv7_2'] = Convolution2D(256, 3, 3, subsample=(2, 2),\n",
    "                                   activation='relu', border_mode='valid',\n",
    "                                   name='conv7_2')(net['conv7_2'])\n",
    "    # Block 8\n",
    "    net['conv8_1'] = Convolution2D(128, 1, 1, activation='relu',\n",
    "                                   border_mode='same',\n",
    "                                   name='conv8_1')(net['conv7_2'])\n",
    "    net['conv8_2'] = Convolution2D(256, 3, 3, subsample=(2, 2),\n",
    "                                   activation='relu', border_mode='same',\n",
    "                                   name='conv8_2')(net['conv8_1'])\n",
    "    # Last Pool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FC6 is changed to AtrousConvolution2D layers, which is similar to regular conv, but increase the receptive field. \n",
    "FC7 is changed to regular convolution layer.\n",
    "\n",
    "The next step is to predict location and confidence through the multi-layer feature map obtained by the changed VGG16. The feature maps used are: conv4_3, fc7, conv6_2, conv7_2, conv8_2, pool6. A total of 6 layers of feature map. Because the processing steps for each layer are similar, the code processed by conv4_3 is posted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prediction from conv4_3\n",
    "    net['conv4_3_norm'] = Normalize(20, name='conv4_3_norm')(net['conv4_3'])\n",
    "    num_priors = 3\n",
    "    x = Convolution2D(num_priors * 4, 3, 3, border_mode='same',\n",
    "                      name='conv4_3_norm_mbox_loc')(net['conv4_3_norm'])\n",
    "    net['conv4_3_norm_mbox_loc'] = x\n",
    "    flatten = Flatten(name='conv4_3_norm_mbox_loc_flat')\n",
    "    net['conv4_3_norm_mbox_loc_flat'] = flatten(net['conv4_3_norm_mbox_loc'])\n",
    "    name = 'conv4_3_norm_mbox_conf'\n",
    "    if num_classes != 21:\n",
    "        name += '_{}'.format(num_classes)\n",
    "    x = Convolution2D(num_priors * num_classes, 3, 3, border_mode='same',\n",
    "                      name=name)(net['conv4_3_norm'])\n",
    "    net['conv4_3_norm_mbox_conf'] = x\n",
    "    flatten = Flatten(name='conv4_3_norm_mbox_conf_flat')\n",
    "    net['conv4_3_norm_mbox_conf_flat'] = flatten(net['conv4_3_norm_mbox_conf'])\n",
    "    priorbox = PriorBox(img_size, 30.0, aspect_ratios=[2],\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        name='conv4_3_norm_mbox_priorbox')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that for the feature map of the conv4_3 layer, the number of default boxes used is 3. Therefore, location predicts that the number of convolution kernels used by this convolutional layer is: 3*4=12. Flatten is needed after the convolution, because the final output is concatenate predicted by the multi-layer feature map. Similarly, the number of convolution kernels used for confidence prediction is 21*3=36 (for voc data sets). For the layer of PriorBox, it is only necessary to know that it is corresponding to the feature map to get the default box, and for a specific feature map, it is fixed, not with the process of train or predict. changed.\n",
    "\n",
    "There are some differences in the feature map processing generated by pool6. Here is a separate one, because the pool6 layer uses the globa laverage pool, so its output size is 1*1*256, which is relatively small and is not suitable for volume. After the product is processed, it is processed directly with the Dense layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prediction from pool6\n",
    "    num_priors = 6\n",
    "    x = Dense(num_priors * 4, name='pool6_mbox_loc_flat')(net['pool6'])\n",
    "    net['pool6_mbox_loc_flat'] = x\n",
    "    name = 'pool6_mbox_conf_flat'\n",
    "    if num_classes != 21:\n",
    "        name += '_{}'.format(num_classes)\n",
    "    x = Dense(num_priors * num_classes, name=name)(net['pool6'])\n",
    "    net['pool6_mbox_conf_flat'] = x\n",
    "    priorbox = PriorBox(img_size, 276.0, max_size=330.0, aspect_ratios=[2, 3],\n",
    "                        variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                        name='pool6_mbox_priorbox')\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        target_shape = (1, 1, 256)\n",
    "    else:\n",
    "        target_shape = (256, 1, 1)\n",
    "    net['pool6_reshaped'] = Reshape(target_shape,\n",
    "                                    name='pool6_reshaped')(net['pool6'])\n",
    "\n",
    "    net['pool6_mbox_priorbox'] = priorbox(net['pool6_reshaped'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The prediction results are concatenated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net['mbox_loc'] = merge([net['conv4_3_norm_mbox_loc_flat'],\n",
    "                             net['fc7_mbox_loc_flat'],\n",
    "                             net['conv6_2_mbox_loc_flat'],\n",
    "                             net['conv7_2_mbox_loc_flat'],\n",
    "                             net['conv8_2_mbox_loc_flat'],\n",
    "                             net['pool6_mbox_loc_flat']],\n",
    "                            mode='concat', concat_axis=1, name='mbox_loc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
