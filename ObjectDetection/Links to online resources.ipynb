{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suvey's reference links:\n",
    "https://blog.csdn.net/u012426298/article/details/80747361\n",
    "https://www.jiqizhixin.com/articles/2018-05-22-13 从R-CNN到YOLO，一文带你了解目标检测模型\n",
    "https://blog.csdn.net/mdjxy63/article/details/79344045 目标检测(Object Detection)的整理, mdjxy63\n",
    "https://blog.csdn.net/myarrow/article/details/51878004 cs231n学习笔记-CNN-目标检测、定位、分割, myarrow\n",
    "\n",
    "Yolov1:\n",
    "https://blog.csdn.net/qq_34784753/article/details/78797213 YOLO_v1：You Only Look Once 原理, S大幕 \n",
    "yolov2:\n",
    "https://blog.csdn.net/jesse_mx/article/details/53925356 YOLOv2 论文笔记, Jesse_Mx\n",
    "https://blog.csdn.net/wfei101/article/details/79398563 目标检测：YOLOv2算法详解, BigCowPeking\n",
    "\n",
    "yolo_v3:\n",
    "https://blog.csdn.net/l7H9JA4/article/details/79991772 目标检测|YOLOv2原理与实现(附YOLOv3), I7H9JA4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fast R-CNN\n",
    "\n",
    "2015年，R-CNN的作者Ross Girshick解决了R-CNN训练慢的问题，发明了新的网络\n",
    "Fast R-CNN。主要突破是引入感兴趣区域池化（ROI Pooling），以及将所有模型整\n",
    "合到一个网络中。\n",
    "你可以通过以下GitHub链接查看模型的各种实现代码：\n",
    "\n",
    "https://github.com/rbgirshick/fast-rcnn\n",
    "\n",
    "https://github.com/precedenceguo/mx-rcnn\n",
    "\n",
    "https://github.com/mahyarnajibi/fast-rcnn-torch\n",
    "\n",
    "https://github.com/apple2373/chainer-simple-fast-rnn\n",
    "\n",
    "https://github.com/zplizzi/tensorflow-fast-rcnn\n",
    "\n",
    "这里还有一个利用对抗学习改进目标检测结果的应用：\n",
    "\n",
    "http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf\n",
    "\n",
    "https://github.com/xiaolonw/adversarial-frcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster R-CNN\n",
    "2015年，一个来自微软的团队（任少卿，何恺明，Ross Girshick和孙剑）发现了一种叫\n",
    "做“Faster R-CNN”的网络结构，基于区域建议网络进行实时目标检测，重复利用多个区域\n",
    "建议中相同的CNN结果，几乎把边框生成过程的运算量降为0。\n",
    "Keras版Faster-RCNN代码学习（IOU，RPN）1\n",
    "https://blog.csdn.net/qq_34564612/article/details/78881689\n",
    "keras版faster-rcnn算法详解（1.RPN计算）\n",
    "https://zhuanlan.zhihu.com/p/28585873\n",
    "keras版faster-rcnn算法详解(2.roi计算及其他)\n",
    "https://zhuanlan.zhihu.com/p/29400164\n",
    "你可以在这里看到关于Faster R-CNN的更多介绍，包括PPT和GitHub代码实现：\n",
    "\n",
    "http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf\n",
    "\n",
    "Matlab\n",
    "\n",
    "https://github.com/ShaoqingRen/faster_rcnn\n",
    "\n",
    "Caffe\n",
    "\n",
    "https://github.com/rbgirshick/py-faster-rcnn\n",
    "\n",
    "MXNet\n",
    "\n",
    "https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn\n",
    "\n",
    "PyTorch\n",
    "\n",
    "https://github.com//jwyang/faster-rcnn.pytorch\n",
    "\n",
    "TensorFlow\n",
    "\n",
    "https://github.com/smallcorgi/Faster-RCNN_TF\n",
    "\n",
    "Keras\n",
    "\n",
    "https://github.com/yhenon/keras-frcnn\n",
    "\n",
    "C++\n",
    "\n",
    "https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPP-Net\n",
    "SPP-Net是基于空间金字塔池化后的深度学习网络进行视觉识别。它和R-CNN的区别是，输入不需要放缩到指定大小，同时增加了一个空间金字塔池化层，每幅图片只需要提取一次特征。\n",
    "\n",
    "相关资源：\n",
    "\n",
    "https://github.com/ShaoqingRen/SPP_net\n",
    "\n",
    "http://zhangliliang.com/2014/09/13/paper-note-sppnet/\n",
    "\n",
    "更多论文：\n",
    "\n",
    "DeepID-Net：基于变形深度卷积神经网络进行目标检测\n",
    "\n",
    "http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html\n",
    "\n",
    "深度感知卷积神经网络中的目标检测器\n",
    "\n",
    "https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf\n",
    "\n",
    "segDeepM：利用深度神经网络中的分割和语境进行目标检测\n",
    "\n",
    "https://github.com/YknZhu/segDeepM\n",
    "\n",
    "基于卷积特征激活图的目标检测网络\n",
    "\n",
    "http://arxiv.org/abs/1504.06066\n",
    "\n",
    "利用贝叶斯优化与结构化预测改进基于深度卷积神经网络的目标检测\n",
    "\n",
    "http://arxiv.org/abs/1504.03293\n",
    "\n",
    "DeepBox：利用卷积网络学习目标特性\n",
    "\n",
    "http://arxiv.org/abs/1505.02146\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO\n",
    "YOLO是指标准化、实时的目标检测。\n",
    "\n",
    "可以先看大数据文摘翻译的这个视频了解YOLO：\n",
    "\n",
    "TED演讲 | 计算机是怎样快速看懂图片的：比R-CNN快1000倍的YOLO算法\n",
    "\n",
    "有了YOLO，不需要一张图像看一千次，来产生检测结果，你只需要看一次，这就是我们为什么把它叫\"YOLO\"物体探测方法（You only look once）。\n",
    "\n",
    "\n",
    "代码实现：\n",
    "\n",
    "https://github.com/pjreddie/darknet\n",
    "\n",
    "https://github.com/gliese581gg/YOLO_tensorflow\n",
    "\n",
    "https://github.com/xingwangsfu/caffe-yolo\n",
    "\n",
    "https://github.com/tommy-qichang/yolo.torch\n",
    "\n",
    "https://github.com/nilboy/tensorflow-yolo\n",
    "\n",
    "相关应用：\n",
    "\n",
    "Darkflow：将darknet转换到tesorflow平台。加载训练好的权值，用tensorflow再次训练，再将导出计算图到C++环境中。\n",
    "\n",
    "https://github.com/thtrieu/darkflow\n",
    "\n",
    "使用你自己的数据训练YOLO模型。利用分类标签和自定义的数据进行训练，darknet支持Linux / Windows系统。\n",
    "\n",
    "https://github.com/Guanghan/darknet\n",
    "    \n",
    "IOS上的YOLO实战：CoreML vs MPSNNGraph，用CoreML和新版MPSNNGraph的API实现小型YOLO。\n",
    "\n",
    "https://github.com/hollance/YOLO-CoreML-MPSNNGraph\n",
    "\n",
    "安卓上基于TensorFlow框架运行YOLO模型实现实时目标检测。\n",
    "\n",
    "https://github.com/natanielruiz/android-yolo    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLOv2模型\n",
    "时隔一年，YOLO作者放出了v2版本，称为YOLO9000，并直言它“更快、更高、更强”。YOLO v2的主要改进是提高召回率和定位能力。\n",
    "物体检测论文-YOLO系列\n",
    "https://www.jianshu.com/p/d792894f1688?utm_campaign=haruki&utm_content=note&utm_medium=reader_share&utm_source=weixin\n",
    "http://hellodfan.com/2017/10/11/%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E8%AE%BA%E6%96%87-YOLO%E7%B3%BB%E5%88%97/\n",
    "    \n",
    "各种实现：\n",
    "\n",
    "Keras\n",
    "\n",
    "https://github.com/allanzelener/YAD2K\n",
    "\n",
    "PyTorch\n",
    "\n",
    "https://github.com/longcw/yolo2-pytorch\n",
    "\n",
    "Tensorflow\n",
    "\n",
    "https://github.com/hizhangp/yolo_tensorflow\n",
    "\n",
    "Windows\n",
    "\n",
    "https://github.com/AlexeyAB/darknet\n",
    "\n",
    "Caffe\n",
    "\n",
    "https://github.com/choasUp/caffe-yolo9000\n",
    "\n",
    "相关应用：\n",
    "\n",
    "Darknet_scripts是深度学习框架中YOLO模型中darknet的辅助脚本，生成YOLO模型中的参数anchors。\n",
    "\n",
    "https://github.com/Jumabek/darknet_scripts\n",
    "\n",
    "Yolo_mark：图形化标记用于训练YOLOv2模型的图像目标\n",
    "\n",
    "https://github.com/AlexeyAB/Yolo_mark\n",
    "\n",
    "LightNet：改进的DarkNet\n",
    "\n",
    "https://github.com//explosion/lightnet\n",
    "\n",
    "用于生成YOLOv2模型所需训练数据的边界框标记工具\n",
    "\n",
    "https://github.com/Cartucho/yolo-boundingbox-labeler-GUI\n",
    "\n",
    "Loss Rank Mining：基于实时目标检测的一种通用的困难样本挖掘方法。LRM是第一个高度适用于YOLOv2模型中的困难样本挖掘策略，它让YOLOv2模型能够更好的应用到对实时与准确率要求较高的场景中。\n",
    "\n",
    "https://arxiv.org/abs/1804.04606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLOv3模型\n",
    "再次改进YOLO模型。提供多尺度预测和更好的基础分类网络。相关实现：\n",
    "\n",
    "https://pjreddie.com/darknet/yolo/\n",
    "\n",
    "https://github.com/pjreddie/darknet\n",
    "\n",
    "https://github.com/experiencor/keras-yolo3\n",
    "\n",
    "https://github.com/marvis/pytorch-yolo3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSD (Single Shot MultiBox Detector)\n",
    "SSD可以说是YOLO和Faster R-Cnn两者的优势结合。相比于Faster R-Cnn，SSD的目标检测速度显著提高，精度也有一定提升；相比YOLO，速度接近，但精度更高。\n",
    "SSD 算法详解 及其 keras 实现（上）\n",
    "https://blog.csdn.net/remanented/article/details/79943418\n",
    "SSD算法详解 及其 keras实现 （下）\n",
    "https://blog.csdn.net/remanented/article/details/79958942\n",
    "相关实现:\n",
    "\n",
    "https://github.com/zhreshold/mxnet-ssd\n",
    "\n",
    "https://github.com/rykov8/ssd_keras\n",
    "\n",
    "https://github.com/balancap/SSD-Tensorflow\n",
    "\n",
    "https://github.com/amdegroot/ssd.pytorch\n",
    "\n",
    "https://github.com/chuanqi305/MobileNet-SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DSOD\n",
    "与SSD类似，是一个多尺度不需要proposal的检测框架，是一种完全脱离预训练模型的深度监督目标检测方法。\n",
    "\n",
    "相关实现：\n",
    "\n",
    "https://arxiv.org/abs/1708.01241\n",
    "\n",
    "https://github.com/szq0214/DSOD\n",
    "\n",
    "https://github.com/Windaway/DSOD-Tensorflow\n",
    "\n",
    "https://github.com/chenyuntc/dsod.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
